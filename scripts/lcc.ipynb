{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch.losses as losses\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../new_data_lcc'\n",
    "MODEL_NAME = 'SegformerJaccardLoss'\n",
    "\n",
    "SAR_DIR = os.path.join(DATA_DIR, 'sar')\n",
    "MASK_DIR = os.path.join(DATA_DIR, 'ground_truth')\n",
    "WEIGHTS_DIR = '../weights'\n",
    "PREDICTIONS_DIR = os.path.join('../predictions_lcc', MODEL_NAME)\n",
    "\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "N_CHANNELS = 3\n",
    "\n",
    "COLOR_MAP = {\n",
    "    (65, 155, 223): 1,   # 0x419bdf -> Water\n",
    "    (57, 125, 73): 2,    # 0x397d49 -> Trees\n",
    "    (122, 135, 198): 4,  # 0x7a87c6 -> Flooded Vegetation\n",
    "    (228, 150, 53): 5,   # 0xe49635 -> Crops\n",
    "    (196, 40, 27): 7,    # 0xc4281b -> Built Area\n",
    "    (165, 155, 143): 8,  # 0xa59b8f -> Bare Ground\n",
    "    #(168, 235, 255): 9,  # 0xa8ebff -> Snow/Ice\n",
    "    #(97, 97, 97): 10,    # 0x616161 -> Clouds\n",
    "    (227, 226, 195): 11, # 0xe3e2c3 -> Rangeland\n",
    "}\n",
    "\n",
    "CLASS_LABELS = [1, 2, 4, 5, 7, 8, 11]\n",
    "LABEL_TO_INDEX = {label: i for i, label in enumerate(CLASS_LABELS)}\n",
    "INDEX_TO_COLOR = {v: k for k, v in COLOR_MAP.items()}\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Number of classes: {len(CLASS_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandCoverDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, image_ids, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_ids = image_ids\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def _rgb_to_mask(self, rgb_mask):\n",
    "        mask = np.zeros((rgb_mask.shape[0], rgb_mask.shape[1]), dtype=np.int64)\n",
    "        for color, label in COLOR_MAP.items():\n",
    "            locations = np.where(np.all(rgb_mask == color, axis=-1))\n",
    "            mask[locations] = LABEL_TO_INDEX[label]\n",
    "        return torch.from_numpy(mask)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, img_name)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask_rgb = np.array(Image.open(mask_path).convert(\"RGB\"))\n",
    "\n",
    "        mask = self._rgb_to_mask(mask_rgb)\n",
    "\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "class TrainTransform:\n",
    "    def __call__(self, image, mask):\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask = TF.vflip(mask)\n",
    "\n",
    "        angle = random.choice([0, 90, 180, 270])\n",
    "        image = TF.rotate(image, angle)\n",
    "        mask = TF.rotate(mask.unsqueeze(0), angle, interpolation=transforms.InterpolationMode.NEAREST).squeeze(0)\n",
    "\n",
    "        image = TF.to_tensor(image)\n",
    "        image = TF.normalize(image, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        return image, mask\n",
    "\n",
    "class ValTestTransform:\n",
    "    def __call__(self, image, mask):\n",
    "        image = TF.to_tensor(image)\n",
    "        image = TF.normalize(image, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = sorted([f for f in os.listdir(SAR_DIR) if f.endswith('.png')])\n",
    "random.seed(42)\n",
    "random.shuffle(all_files)\n",
    "\n",
    "n_files = len(all_files)\n",
    "train_split = int(n_files * 0.7)\n",
    "val_split = int(n_files * 0.85)\n",
    "\n",
    "train_ids = all_files[:train_split]\n",
    "val_ids = all_files[train_split:val_split]\n",
    "test_ids = all_files[val_split:]\n",
    "\n",
    "train_dataset = LandCoverDataset(SAR_DIR, MASK_DIR, train_ids, transform=TrainTransform())\n",
    "val_dataset = LandCoverDataset(SAR_DIR, MASK_DIR, val_ids, transform=ValTestTransform())\n",
    "test_dataset = LandCoverDataset(SAR_DIR, MASK_DIR, test_ids, transform=ValTestTransform())\n",
    "\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Total images: {n_files}\")\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(loader, desc=\"Training\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.to(device=DEVICE, dtype=torch.long)\n",
    "\n",
    "        predictions = model(data)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate_model(loader, model, loss_fn):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(loader, desc=\"Evaluating\")\n",
    "        for data, targets in loop:\n",
    "            data = data.to(device=DEVICE)\n",
    "            targets = targets.to(device=DEVICE, dtype=torch.long)\n",
    "            \n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(predictions, dim=1)\n",
    "            num_correct += (preds == targets).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), accuracy=f\"{(num_correct/num_pixels)*100:.2f}%\")\n",
    "\n",
    "    accuracy = (num_correct / num_pixels) * 100\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Segformer(encoder_name='efficientnet-b7', classes=len(CLASS_LABELS)).to(DEVICE)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = losses.JaccardLoss(mode='multiclass')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "model_save_path = os.path.join(WEIGHTS_DIR, f\"{MODEL_NAME}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs_no_improve = 0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n",
    "    \n",
    "    train_loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    val_loss, val_accuracy = evaluate_model(val_loader, model, loss_fn)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Accuracy={val_accuracy:.2f}%\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Validation loss improved. Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in validation loss for {epochs_no_improve} epoch(s).\")\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping triggered. No improvement in {PATIENCE} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mask_to_rgb(mask_tensor, class_map):\n",
    "    mask_np = mask_tensor.cpu().numpy()\n",
    "    rgb_image = np.zeros((mask_np.shape[0], mask_np.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_idx, color in class_map.items():\n",
    "        original_label = CLASS_LABELS[class_idx]\n",
    "        rgb_color = INDEX_TO_COLOR[original_label]\n",
    "        rgb_image[mask_np == class_idx] = rgb_color\n",
    "        \n",
    "    return Image.fromarray(rgb_image)\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"Water\",\n",
    "    \"Trees\",\n",
    "    \"Flooded Vegetation\",\n",
    "    \"Crops\",\n",
    "    \"Built Area\",\n",
    "    \"Bare Ground\",\n",
    "    \"Rangeland\",\n",
    "]\n",
    "\n",
    "epsilon = 1e-6\n",
    "conf_matrix = np.zeros((len(CLASS_LABELS), len(CLASS_LABELS)), dtype=np.int64)\n",
    "total_correct = 0\n",
    "total_pixels = 0\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_path, weights_only=True))\n",
    "print(f\"Loaded best weights from {model_save_path} for final evaluation.\")\n",
    "\n",
    "print(f\"\\nSaving test predictions to {PREDICTIONS_DIR} and evaluating metrics...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(tqdm(test_dataset, desc=\"Evaluating Model\")):\n",
    "        x = x.unsqueeze(0).to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        preds = torch.argmax(model(x), dim=1).squeeze(0)\n",
    "        y_true = y.squeeze(0)\n",
    "\n",
    "        pred_rgb = mask_to_rgb(preds, {i: v for i, v in enumerate(CLASS_LABELS)})\n",
    "        original_filename = test_ids[i]\n",
    "        pred_rgb.save(os.path.join(PREDICTIONS_DIR, original_filename))\n",
    "\n",
    "        preds_np = preds.cpu().numpy().flatten()\n",
    "        y_np = y_true.cpu().numpy().flatten()\n",
    "\n",
    "        total_correct += (preds_np == y_np).sum()\n",
    "        total_pixels += y_np.size\n",
    "\n",
    "        conf_matrix += confusion_matrix(y_np, preds_np, labels=list(range(len(CLASS_LABELS))))\n",
    "\n",
    "tp = np.diag(conf_matrix)\n",
    "\n",
    "fp = np.sum(conf_matrix, axis=0) - tp\n",
    "\n",
    "fn = np.sum(conf_matrix, axis=1) - tp\n",
    "\n",
    "iou_per_class = tp / (tp + fp + fn + epsilon)\n",
    "dice_per_class = (2 * tp) / (2 * tp + fp + fn + epsilon)\n",
    "\n",
    "pixel_accuracy = total_correct / total_pixels\n",
    "mean_iou = np.nanmean(iou_per_class)\n",
    "mean_dice = np.nanmean(dice_per_class)\n",
    "\n",
    "print(\"\\n--- Test Set Performance ---\")\n",
    "print(f\"Test Pixel Accuracy: {pixel_accuracy * 100:.2f}%\")\n",
    "print(f\"Mean IoU (from aggregated matrix): {mean_iou:.4f}\")\n",
    "print(f\"Mean Dice Coefficient (from aggregated matrix): {mean_dice:.4f}\")\n",
    "\n",
    "print(\"\\n--- Per-Class Metrics (from aggregated matrix) ---\")\n",
    "for i, label in enumerate(CLASS_LABELS):\n",
    "    print(f\"{label}: IoU = {iou_per_class[i]:.4f}, Dice = {dice_per_class[i]:.4f}\")\n",
    "\n",
    "output_dir = '../results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': pixel_accuracy,\n",
    "    'iou': mean_iou,\n",
    "    'dice': mean_dice\n",
    "}\n",
    "metrics_path = os.path.join(output_dir, f'{MODEL_NAME}.json')\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "print(f\"\\nSaved metrics to {metrics_path}\")\n",
    "\n",
    "cm_df = pd.DataFrame(conf_matrix,\n",
    "                     index = CLASS_NAMES,\n",
    "                     columns = CLASS_NAMES)\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "cm_img_path = os.path.join(output_dir, f'{MODEL_NAME}.png')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(cm_img_path, bbox_inches='tight')\n",
    "print(f\"Saved confusion matrix heatmap to {cm_img_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
